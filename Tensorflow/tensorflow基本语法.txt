概念
graphs:计算任务
Session:上下文context中的执行图
tensor表示数据
Variable变量维护状态
feed,fetch任意赋值或者获取数据
import tensorflow as tf
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
函数：常量（常量无需对图进行初始化处理）
tf.constant(value, dtype=None, shape=None, name='Const')
tf.constant([1,2])用于创造一个矩阵为1行2列格式
tensor("xx_1:0",shape=(2,0),dtype=int32)
函数constant有五个参数，分别为value，name，dtype，shape和verify_shape。
value为必选参数，其它均为可选参数。[1,2]
Value为常量的具体值，可以是一个数字，一维向量或是多维矩阵。
Name是常量的名字，用于区别其它常量。
Dtype是常量的类型(如INT32 INT64,FLOAT32,STING)
Shape是指常量的维度，我们可以自行定义常量的维度
verify_shape是验证shape是否正确
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
函数变量（需要构造初始化图）          矩阵2行三列
变量，tf.Variable(tf.random_normal([2,3],stddev=2,mean=0,seed=1))
tf.random_normal():正态分布
tf.truncated_normal():去掉过大偏离点的正态分布
tf.random_uniform():平均分布
stddev=2：标准差为2
mean=0:均值为0
seed=1:随机种子为1
需要初始化所有变量
激活名称=tf.initialize_all_variables()
用sess.run(激活名称)激活状态

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
占位符:tf.placeholder
创建一个占位函数
一组数据方式
tf.placeholder(tf.float32,shape(1,2))输入1行两列数据
(y,feed_dict{x:[[0.5,0.6]]}))
多组数据方式
tf.placeholder(tf.float32,shape(NONE,2))不限行数，限定列数为2列
(y,feed_dict{x:[[0.5,0.6],[0.3,0.4]]}))
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
激励函数(解决非线性方程）
tf.nn.relu(features,name=None):当传入的值小于0的时候等于0，当传入值得时候大于0就等于一个直线上升的方程
tf.nn.relu6(features,name=None)
tf.nn.elu(features,name=None)
tf.nn.softplus(features,name=None)
tf.nn.softsign(features,name=None)
tf.nn.duopout(x,keep_prob,noise_shape=None,seed=None,name=None)
tf.nn.bias_add(value,bias,data_format=None,name=None)
tf.sigmoid(x,nanme=None)
tf.tanh(x,name=None)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
常量的初始化方法
tf.zeros(shape, dtype=tf.float32, name=None ) ：为0的矩阵矩阵参数（[2,2]）全0的数据
tf.zeros_like(tensor, dtype=None, name=None)
tf.ones:为1的矩阵矩阵参数（[2,2]）全一数组
tf.ones_like(tensor, dtype=None, name=None)
tf.fill：图形中创建一个Op,在运行时展开动态的展开，全定值数组
tf.linspace(start, end, num)start代表起始的值，end表示结束的值，num表示在这个区间里生成数字的个数start和end这两个数字必须是浮点数，不能是整数
tf.range:随机生成矩阵
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
tf.add()用于对矩阵进行相加操作
tf.assign（a变量，新的值）就是在通过实际计算后的值，用新的值赋值给a的初始化变量，类似迭代累加方式

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
tf.Session()创造一个回话框用于打印数据显示
例子：
sess=tf.Session()函数赋值给sess
sess.run()执行函数内容
sess.close需要手动释放资源
例子2：系统自动释放资源方式
with tf.Session() as sess:
  total=sess.run(名称)
print(total)

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
tf.device(“/gpu:2”)用于选择多个GPU情况可以选择GPU进行运算
方法：
with tf.Session() as sess:
  with tf.device(“/gpu:2”)：
  其他内容与tf.Session例子执行方式一致
  
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
tf.as_default()自动回话框函数方法
with tf.as_default()
  print(result.eval())求值数调用eval方法

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
tf.InteractiveSession()可以直接使用此函数来调用回话
print(result.eval)

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 





