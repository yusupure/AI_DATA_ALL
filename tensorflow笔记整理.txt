第一课 基础了解
维数    阶     名字    例子
0-D     0     标量    S=123
1-D     1     向量    S=[1,2,3]
2-D     2     矩阵    S=[[1,2,3],[4,5,6]]
3-D     3     张量    S=[[[1,2,3],[4,5,6]]

X=tf.constant[[1.0,2.O]]
W1=tf.constant[[3.0,4.0]]
矩阵乘法
x1=1.0*w1=3.0
x2=2.0*w1=4.0
相乘后的结果进行相加=11.0
公式为：y=x1w1+x2w2

tensorflow需要创建会话才能进行计算，会话方式有两种
1.with tf.Session()as sess:          2.sess=tf.Session()
  sess.run(参数Y)                       sess.run(参数Y）
注解：
第一种方式系统自动在会话结束后自动关闭
第二种方法需要手工添加sess.close()进行会话关闭
----------------------------------------------------------------------------------------------------------------------------------------
第二课 前向传播
由于需要创建数据集来进行数据计算，TENSORFLOW有以下数据自建方法:

w=tf.Variable(tf.random_normal([2,3],stddev=2,mean=0,seed=1)
1.tf.Variable=创建一个变量的方法，但计算的时候必须创建会话进行计算，否则不会进行数据打印，sess.run(参数）
1.1 tf.random_normal=一个正态分布（[2,3]=2*3的矩阵，stddev=标准差，mean=均值，seed=随机种子）
1.2 tf.truncated_normal()=去掉偏离点的正态分布
1.3 tf.random.uniform()=平均分布
1.4 tf.zeros()=全部为0的数组 例：tf.zeros([2,3])创建为三行两列的数据[[0,0][0,0]],[[0,0][0,0]],[[0,0][0,0]]
1.5 tf.ones()=全部为1的数组 例：tf.zeros([2,3])创建为三行两列的数据[[1,1][1,1]],[1,1][1,1]],[[1,1][1,1]]
1.6 tf.fill()=全定值数组 例：tf.fill([2,3],6)|6代表设置值|下面的均值默认值为6 创建为三行两列的数据[[6,6][6,6]],[6,6][6,6]],[[6,6][6,6]]
1.7 tf.constant()=直接输出值 例：tf.constant(6),6就代表为输出值

神经网络实现原理过程
1.准备数据集，提取特征，作为输入喂给神经网络
2.搭建NN结构，从输入到输出：（先搭建计算图，在进行会话执行）
  （NN前向传播算法--》计算输出）
3.大量特征喂给NN，迭代优化NN的参数
  （NN反向传播算法--》优化参数模型）
4.使用训练好的模型预测及分类

----------------------------------------------------------------------------------------------------------------------------------------
第三课 反向传播
反向传播：在所有参数上用梯度下降，使NN模型在训练数据损失函数减少
损失函数（梯度下降法）
loss=预测值-已知答案的差距（PD-y）
默认公式：
Loss=平均值(平方（预测值/已知答案））
例子
loss=tf.reduce_mean(tf.square(预测值/已知答案))
reduce_mean=计算平均值
tf.square=计算两个值相除后的平方

2.方向训练：用于减少Loss值为优先目标
梯度下降法优化器
tf.train.GradientDescentOptimizer(小于1的损失值).minimize(loss)
tf.train.MomentumOptimizer(小于1的损失值).minimize(loss)
tf.train.AdamOptimizer(小于1的损失值).minimize(loss)
